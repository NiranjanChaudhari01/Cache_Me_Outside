# Smart Auto-Labeling with Real-Time Client Feedback

ğŸš€ A hybrid NLP annotation pipeline that combines ML-powered auto-labeling with human review and real-time client feedback.

## ğŸ¯ Problem Statement

- **Pure auto-labeling**: Fast but error-prone on edge cases
- **Pure manual labeling**: Accurate but slow and expensive  
- **Client feedback**: Usually comes too late, causing rework

## ğŸ’¡ Solution

A transparent, collaborative pipeline where:
1. **Auto-labeler** generates initial predictions with confidence scores
2. **Annotators** quickly review/correct instead of labeling from scratch
3. **Client portal** provides real-time visibility and feedback capability
4. **Active learning** loop improves the model with corrections

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Dataset   â”‚â”€â”€â”€â–¶â”‚   Auto-Labeler   â”‚â”€â”€â”€â–¶â”‚ Annotator UI    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client Portal   â”‚â—€â”€â”€â”€â”‚   Database       â”‚â—€â”€â”€â”€â”‚ Feedback Loop   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Note: ALL tasks go through Annotator UI regardless of confidence level
```

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)
```bash
# Run the setup script
python3 setup.py

# Start the entire system
./start_system.sh

# Access the application
# Dashboard: http://localhost:3000
# API Docs: http://localhost:8000/docs
```

### Option 2: Manual Setup
```bash
# Backend setup
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm
python -m uvicorn main:app --reload

# Frontend setup (in new terminal)
cd frontend
npm install
npm start
```

### Option 3: Docker (Production)
```bash
# Start with Docker Compose
docker-compose up --build

# Access the application
# Dashboard: http://localhost:3000
# API Docs: http://localhost:8000/docs
```

## ğŸ“Š Demo Flow

1. **Upload Dataset** â†’ Raw text data
2. **Auto-Label** â†’ ML generates initial predictions
3. **Annotator Review** â†’ Quick corrections with confidence guidance
4. **Client Feedback** â†’ Real-time sample review and approval
5. **Export Results** â†’ High-quality labeled dataset

## ğŸ¯ Business Value

- **40-60% faster** than pure manual labeling
- **Real-time transparency** builds client trust
- **Fewer re-work cycles** through early feedback
- **Continuous improvement** via active learning
